核心及阐述思路：

1. 整个 HTTP 网络协议的发展历程，不同协议之间的相通性与差异点
2. **理解每一次的升级，协议到底在解决之前什么问题？**



## ![img](https://cdn.nlark.com/yuque/0/2023/png/311219/1694250576571-b58fd623-7738-4675-9d3f-b11470a4ce8b.png)

## HTTP

全称：超文本传输协议（HyperText Transfer Protocol）

概念：HTTP 是一种能够获取像 HTML、图片等网络资源的通讯协议（protocol）。它是在 web 上进行数据交换的基础，是一种 client-server 协议

HTTP——因特网的多媒体信使 ——《HTTP权威指南》。 HTTP 在因特网的角色：充当一个信使的角色，干的就是一个跑腿的活，在客户端和服务端之间传递信息，但我们又不能缺少它。HTTP 协议是应用层的协议，是与前端开发最息息相关的协议。平时我们遇到的 HTTP 请求、 HTTP 缓存、Cookies、跨域等其实都跟 HTTP 息息相关

### 基础特点

- 可拓展协议。HTTP 1.0 出现的 HTTP headers 让协议拓展变得更加的容易。只要服务端和客户端就 headers 达成语义一致，新功能就可以被轻松的加入进来
- HTTP **是无状态的、有会话的**。在同一个连接中，两个执行成功的 HTTP 请求之间是没有关系的。这就带来了一个问题，用户没有办法在同一个网站中进行连续的交互，比如在一个电商网站里，用户把某个商品加入到购物车，切换一个页面后再次添加了商品，这两次添加商品的请求之间没有关联，浏览器无法知道用户最终选择了哪些商品。而使用 HTTP 的头部扩展，HTTP Cookies 就可以解决这个问题。把 Cookies 添加到头部中，创建一个会话让每次请求都能共享相同的上下文信息，达成相同的状态。
- HTTP 与连接。通过 TCP，或者 TLS——加密的 TCP 连接来发送，理论上任何可靠的传输协议都可以使用。连接是传输层控制的，这从根本上来讲不是 HTTP 的范畴。

![img](https://cdn.nlark.com/yuque/0/2023/png/311219/1694249295145-39648986-1094-4272-8625-eb4034aed409.png)

也就是说，HTTP 依赖于面向连接的 TCP 进行消息传递，但连接并不是必须的。只需要它是可靠的，或不丢失消息的（至少返回错误）。

### HTTP 0.9

单行协议，请求由单行指令构成。以唯一可用的方法 GET 开头。后面跟的是目标资源的路径

```plain
GET /mypage.html
```

响应：只包括响应文档本身

```html
<HTML>
这是一个非常简单的HTML页面
</HTML>
```

- 没有响应头，只传输 HTML 文件
- 没有状态码



### HTTP 1.0

[RFC 1945](https://link.juejin.cn?target=https%3A%2F%2Ftools.ietf.org%2Fhtml%2Frfc1945) 提出了 HTTP1.0，**构建更好可拓展性**

- 协议版本信息会随着每个请求发送
- 响应状态码
- 引入了 HTTP 头的概念，无论是请求还是拓展，允许传输元数据。使协议变得灵活，更加具有拓展性
- Content-Type 请求头，具备了传输除纯文本 HTML 文件以外其他类型文档的能力 在响应中，Content-Type 标头告诉客户端实际返回的内容的内容类型

媒体类型是一种标准。用来表示文档、文件或者字节流的性质和格式。浏览器通常使用 MIME （Multipurpose Internet Mail Extensions ）类型来确定如何处理 URL，因此 Web 服务器在响应头中配置正确的 MIME 类型会非常的重要。如果配置不正确，可能会导致网站无法正常的工作。MIME 的组成结构非常简单；由类型与子类型两个字符串中间用'/'分隔而组成。

HTTP 从 MIME type 取了一部分来标记报文 body 部分的数据类型，这些类型体现在Content-Type 这个字段，当然这是针对于发送端而言，接收端想要收到特定类型的数据，也可以用 Accept 字段。

这两个字段的取值可以分为下面几类:

```plain
- text： text/html, text/plain, text/css 等
- image: image/gif, image/jpeg, image/png 等
- audio/video: audio/mpeg, video/mp4 等
- application: application/json, application/javascript, application/pdf, application/octet-stream
```

同时为了约定请求的数据和响应数据的压缩方式、支持语言、字符集等，还提出了以下的 Header

1.压缩方式:发送端：Content-Encoding（服务端告知客户端，服务器对实体的主体部分的编码方式） 和 接收端：Accept-Encoding（用户代理支持的编码方式），值有 gzip: 当今最流行的压缩格式；deflate: 另外一种著名的压缩格式；br: 一种专门为 HTTP 发明的压缩算法

2.支持语言：Content-Language 和 Accept-Language（用户代理支持的自然语言集）

3.字符集：发送端：Content-Type 中，以 charset 属性指定。接收端： Accept-Charset（用户代理支持的字符集）。

```html
// 发送端
Content-Encoding: gzip
Content-Language: zh-CN, zh, en
Content-Type: text/html; charset=utf-8

// 接收端
Accept-Encoding: gzip
Accept-Language: zh-CN, zh, en
Accept-Charset: charset=utf-8
```

虽然 HTTP1.0 在 HTTP 0.9 的基础上改进了很多，但还是存在不少的缺点。

#### HTTP 1.0 的缺点

HTTP/1.0 版的主要缺点是，**每个 TCP 连接只能发送一个请求。发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接。 TCP 连接的新建成本很高，因为需要客户端和服务器三次握手，并且开始时发送速率较慢（slow start）。**

HTTP 最早期的模型，也是 HTTP/1.0 的默认模型，是短连接。每一个 HTTP 请求都由它自己独立的连接完成；这意味着发起每一个 HTTP 请求之前都会有一次 TCP 握手，而且是连续不断的。



### HTTP 1.1

HTTP/1.1 在1997年1月以 [RFC 2068](https://link.juejin.cn?target=https%3A%2F%2Ftools.ietf.org%2Fhtml%2Frfc2068) 文件发布。

HTTP 1.1 消除了大量歧义内容并引入了多项技术

- 连接可以复用。长连接：connection: keep-alive。HTTP 1.1 支持长连接（PersistentConnection），在一个 TCP 连接上可以传送多个 HTTP 请求和响应，减少了建立和关闭连接的消耗和延迟，在 HTTP1.1 中默认开启 Connection： keep-alive，一定程度上弥补了 HTTP1.0 每次请求都要创建连接的缺点。
- 增加了管道化技术（HTTP Pipelinling），允许在第一个应答被完全发送完成之前就发送第二个请求，以降低通信延迟。复用同一个 TCP 连接期间，即便是通过管道同时发送了多个请求，服务端也是按请求的顺序依次给出响应的；而客户端在未收到之前所发出所有请求的响应之前，将会阻塞后面的请求(排队等待)，这称为"队头堵塞"（Head-of-line blocking）。
- 支持响应分块，分块编码传输：Transfer-Encoding: chunkedContent-length 声明本次响应的数据长度。keep-alive 连接可以先后传送多个响应，因此用 Content-length 来区分数据包是属于哪一个响应。 使用 Content-Length 字段的前提条件是，服务器发送响应之前，必须知道响应的数据长度。 对于一些很耗时的动态操作来说，这意味着，服务器要等到所有操作完成，才能发送数据，显然这样的效率不高。更好的处理方法是，产生一块数据，就发送一块，采用"流模式"（Stream）取代"缓存模式"（Buffer）。因此，HTTP 1.1 规定可以不使用 Content-Length 字段，而使用"分块传输编码"（Chunked Transfer Encoding）。只要请求或响应的头信息有 Transfer-Encoding: chunked 字段，就表明 body 将可能由数量未定的多个数据块组成。 每个数据块之前会有一行包含一个 16 进制数值，表示这个块的长度；最后一个大小为 0 的块，就表示本次响应的数据发送完了。
- 引入额外的缓存控制机制。在 HTTP1.0 中主要使用 header 里的 If-Modified-Since,Expires 等来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如 Entity tag, If-None-Match，Cache-Control 等更多可供选择的缓存头来控制缓存策略。
- Host 头。不同的域名配置同一个 IP 地址的服务器。Host 是 HTTP 1.1 协议中新增的一个请求头，主要用来实现虚拟主机技术。

虚拟主机（virtual hosting）即共享主机（shared web hosting），可以利用虚拟技术把一台完整的服务器分成若干个主机，因此可以在单一主机上运行多个网站或服务。

举个栗子，有一台 ip 地址为 61.135.169.125 的服务器，在这台服务器上部署着谷歌、百度、淘宝的网站。为什么我们访问 https://www.google.com 时，看到的是 Google 的首页而不是百度或者淘宝的首页？原因就是 Host 请求头决定着访问哪个虚拟主机。

## HTTPS

HTTPS 也是通过 HTTP 协议进行传输信息，但是采用了 TLS 协议进行了加密。

HTTPS 的整体过程分为**证书验证**和**数据传输**阶段，具体的交互过程如下：

[![img](https://cdn.nlark.com/yuque/0/2023/webp/311219/1694249776138-49df394b-c53e-4a66-92bb-57293be7a978.webp)](https://link.juejin.cn?target=https%3A%2F%2Fstatic.blog.leapmie.com%2F2019%2F11%2F1378987910.png)

**① 证书验证阶段**

1. 浏览器发起 HTTPS 请求
2. 服务端返回 HTTPS 证书
3. 客户端验证证书是否合法，如果不合法则提示告警

**② 数据传输阶段**

1. 当证书验证合法后，在本地生成随机数
2. 通过公钥加密随机数，并把加密后的随机数传输到服务端
3. 服务端通过私钥对随机数进行解密
4. 服务端通过客户端传入的随机数构造对称加密算法，对返回结果内容进行加密后传输

### HTTP 与 HTTPS 的区别

- HTTP 是明文传输，HTTPS 通过 SSL\TLS 进行了加密
- HTTP 的端口号是 80，HTTPS 是 443
- HTTPS 需要到 CA 申请证书，一般免费证书很少，需要交费
- HTTPS 的连接很简单，是无状态的；HTTPS 协议是由 SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 HTTP 协议安全。

### 对称加密和非对称加密

对称加密就是两边拥有相同的秘钥，两边都知道如何将密文加密解密。但是因为传输数据都是走的网络，如果将秘钥通过网络的方式传递的话，一旦秘钥被截获就没有加密的意义的

非对称加密

公钥大家都知道，可以用公钥加密数据。但解密数据必须使用私钥，私钥掌握在颁发公钥的一方。首先服务端将公钥发布出去，那么客户端是知道公钥的。然后客户端创建一个秘钥，并使用公钥加密，发送给服务端。服务端接收到密文以后通过私钥解密出正确的秘钥

### TLS 握手过程

TLS 握手的过程采用的是**非对称加密**

- Client Hello: 客户端发送一个随机值(Random1)以及需要的协议和加密方式。
- Server Hello 以及 Certificate: 服务端收到客户端的随机值，自己也产生一个随机值(Random2)，并根据客户端需求的协议和加密方式来使用对应的方式，并且发送自己的证书（如果需要验证客户端证书需要说明）
- Certificate Verify: 客户端收到服务端的证书并验证是否有效，验证通过会再生成一个随机值(Random3)，通过服务端证书的公钥去加密这个随机值并发送给服务端，如果服务端需要验证客户端证书的话会附带证书
- Server 生成 secret: 服务端收到加密过的随机值并使用私钥解密获得第三个随机值(Random3)，这时候两端都拥有了三个随机值，可以通过这三个随机值按照之前约定的加密方式生成密钥，接下来的通信就可以通过该密钥来加密解密

### HTTPS 解决了什么问题？

1. 数据传输的安全性：HTTPS使用SSL（Secure Sockets Layer）或TLS（Transport Layer Security）协议对通信进行加密，确保数据在传输过程中不会被窃取或篡改。这解决了HTTP在传输敏感数据时容易受到拦截和窃听的问题。
2. 身份验证和数据完整性：HTTPS通过使用数字证书对服务器进行身份验证，确保客户端与正确的服务器建立连接。同时，它还提供了数据完整性检查机制，可以防止数据在传输过程中被篡改。
3. SEO（搜索引擎优化）：搜索引擎通常更倾向于显示使用HTTPS的网站，因为它们提供更好的安全性。因此，将网站迁移到HTTPS有助于提高搜索引擎排名和可见性。



### 为什么数据传输是用对称加密？

首先，非对称加密的加解密效率是非常低的，而 http 的应用场景中通常端与端之间存在大量的交互，非对称加密的效率是无法接受的；

另外，在 HTTPS 的场景中只有服务端保存了私钥，一对公私钥只能实现单向的加解密，所以 HTTPS 中内容传输加密采取的是对称加密，而不是非对称加密。

### 什么是中间人攻击？为什么需要 CA 认证机构颁发证书？

HTTP 协议被认为不安全是因为传输过程容易被监听者勾线监听、伪造服务器，而 HTTPS 协议主要解决的便是网络传输的安全性问题。

首先我们假设不存在认证机构，任何人都可以制作证书，这带来的安全风险便是经典的**“中间人攻击”**问题。
“中间人攻击”的具体过程如下：

[![img](https://cdn.nlark.com/yuque/0/2023/webp/311219/1694249819484-142468b0-ec5e-4bc4-b837-957f8b5cf39b.webp)](https://link.juejin.cn?target=https%3A%2F%2Fstatic.blog.leapmie.com%2F2019%2F11%2F2410496311.png)

过程原理：

1. 本地请求被劫持（如DNS劫持等），所有请求均发送到中间人的服务器
2. 中间人服务器返回中间人自己的证书
3. 客户端创建随机数，通过中间人证书的公钥对随机数加密后传送给中间人，然后凭随机数构造对称加密对传输内容进行加密传输
4. 中间人因为拥有客户端的随机数，可以通过对称加密算法进行内容解密
5. 中间人以客户端的请求内容再向正规网站发起请求
6. 因为中间人与服务器的通信过程是合法的，正规网站通过建立的安全通道返回加密后的数据
7. 中间人凭借与正规网站建立的对称加密算法对内容进行解密
8. 中间人通过与客户端建立的对称加密算法对正规内容返回的数据进行加密传输
9. 客户端通过与中间人建立的对称加密算法对返回结果数据进行解密

由于缺少对证书的验证，所以客户端虽然发起的是 HTTPS 请求，但客户端完全不知道自己的网络已被拦截，传输内容被中间人全部窃取。

### 浏览器是如何确保 CA 证书的合法性？

#### 1. 证书包含什么信息？

- 颁发机构信息
- 公钥
- 公司信息
- 域名
- 有效期
- 指纹
- ……

#### 2. 证书的合法性依据是什么？

首先，权威机构是要有认证的，不是随便一个机构都有资格颁发证书，不然也不叫做权威机构。另外，证书的可信性基于信任制，权威机构需要对其颁发的证书进行信用背书，只要是权威机构生成的证书，我们就认为是合法的。所以权威机构会对申请者的信息进行审核，不同等级的权威机构对审核的要求也不一样，于是证书也分为免费的、便宜的和贵的。

#### 3. 浏览器如何验证证书的合法性？

浏览器发起 HTTPS 请求时，服务器会返回网站的 SSL 证书，浏览器需要对证书做以下验证：

1. 验证域名、有效期等信息是否正确。证书上都有包含这些信息，比较容易完成验证；
2. 判断证书来源是否合法。每份签发证书都可以根据验证链查找到对应的根证书，操作系统、浏览器会在本地存储权威机构的根证书，利用本地根证书可以对对应机构签发证书完成来源验证；
   [![img](https://cdn.nlark.com/yuque/0/2023/webp/311219/1694249819525-3b5da134-64c6-49cc-8df8-c847bc23e309.webp)](https://link.juejin.cn?target=https%3A%2F%2Fstatic.blog.leapmie.com%2F2019%2F11%2F1148530856.png)
3. 判断证书是否被篡改。需要与 CA 服务器进行校验；
4. 判断证书是否已吊销。通过CRL（Certificate Revocation List 证书注销列表）和 OCSP（Online Certificate Status Protocol 在线证书状态协议）实现，其中 OCSP 可用于第3步中以减少与 CA 服务器的交互，提高验证效率

以上任意一步都满足的情况下浏览器才认为证书是合法的。

这里插一个我想了很久的但其实答案很简单的问题：
既然证书是公开的，如果要发起中间人攻击，我在官网上下载一份证书作为我的服务器证书，那客户端肯定会认同这个证书是合法的，如何避免这种证书冒用的情况？
其实这就是非加密对称中公私钥的用处，虽然中间人可以得到证书，但私钥是无法获取的，一份公钥是不可能推算出其对应的私钥，中间人即使拿到证书也无法伪装成合法服务端，因为无法对客户端传入的加密数据进行解密。

#### 4. 只有认证机构可以生成证书吗？

如果需要浏览器不提示安全风险，那只能使用认证机构签发的证书。但浏览器通常只是提示安全风险，并不限制网站不能访问，所以从技术上谁都可以生成证书，只要有证书就可以完成网站的 HTTPS 传输。例如早期的 12306 采用的便是手动安装私有证书的形式实现 HTTPS 访问。
[![img](https://cdn.nlark.com/yuque/0/2023/webp/311219/1694249819548-1ba43dbc-d8e9-438c-aa15-cee7c21609f5.webp)](https://link.juejin.cn?target=https%3A%2F%2Fstatic.blog.leapmie.com%2F2019%2F11%2F1504265182.png)

### 本地随机数被窃取怎么办？

证书验证是采用非对称加密实现，但是传输过程是采用对称加密，而其中对称加密算法中重要的随机数是由本地生成并且存储于本地的，HTTPS 如何保证随机数不会被窃取？

其实 HTTPS 并不包含对随机数的安全保证，HTTPS 保证的只是传输过程安全，而随机数存储于本地，本地的安全属于另一安全范畴，应对的措施有安装杀毒软件、反木马、浏览器升级修复漏洞等。

## SPDY

SPDY（Speedy）是一种由 Google 开发的网络协议，旨在提升网页加载速度和性能。SPDY试图优化传输数据的速度和效率，并引入了一些新的特性，如**多路复用**、**请求优先级**和**头部压缩**等。

其实 SPDY 并不是新的一种协议，而是在 HTTP 之前做了一层会话层。 

![img](https://cdn.nlark.com/yuque/0/2023/png/311219/1694249905538-520d0e0c-6d9e-4b1d-8d9b-60990f1fec68.png)

在 2010 年到 2015 年，谷歌通过实践一个实验性的 SPDY 协议，证明了一个在客户端和服务器端交换数据的另类方式。其收集了浏览器和服务器端的开发者的焦点问题，明确了响应数量的增加和解决复杂的数据传输。在启动 SPDY 这个项目时预设的目标是：

- 页面加载时间 (PLT) 减少 50%。
- 无需网站作者修改任何内容。
- 将部署复杂性降至最低，无需变更网络基础设施。
- 与开源社区合作开发这个新协议。
- 收集真实性能数据，验证这个实验性协议是否有效。 为了达到降低目标，减少页面加载时间的目标，SPDY 引入了一个新的二进制分帧数据层，以实现多向请求和响应、优先次序、最小化及消除不必要的网络延迟，目的是更有效地利用底层 TCP 连接。

### SPDY 为什么没有流行起来？

SPDY 没有流行起来是一个复杂的问题，可能有以下一些原因：

1. HTTP/2的出现：SPDY 的设计理念和技术被纳入了 HTTP/2 标准。HTTP/2 是 SPDY 的进一步发展，具有更广泛的支持和兼容性。
2. 兼容性和部署难题：SPDY需要服务器和浏览器双方的支持才能实现其优势。然而，在推广过程中，由于缺乏一致的支持和广泛的部署，它未能在所有平台上得到广泛采用。
3. 技术转移：随着 HTTP/2 的出现，SPDY的特性逐渐被纳入到新的标准中。开发者和组织更倾向于直接采用HTTP/2，从而减少了对 SPDY 的需求和关注度。

虽然SPDY没有成为主流协议，但其对网络性能优化的思想和技术的影响仍然存在，并且这些技术已经被纳入到后续的网络协议标准中。



## HTTP 2.0

### HTTP 1.1 存在什么问题？

为了更好的理解 2.0，我们需要知道 HTTP 发展到 1.1 阶段，存在有哪些问题：

1. 线头阻塞：TCP连接上只能发送一个请求，前面的请求未完成前，后续的请求都在排队等待。
2. 多个TCP连接，虽然HTTP/1.1管线化可以支持请求并发，但是浏览器很难实现，chrome、firefox等都禁用了管线化。所以1.1版本请求并发依赖于多个TCP连接，建立TCP连接成本很高，还会存在慢启动的问题。
3. 头部冗余，采用文本格式
   HTTP/1.X版本是采用文本格式，首部未压缩，而且每一个请求都会带上cookie、user-agent等完全相同的首部。
4. 客户端需要主动请求

基于此，诞生了 HTTP 2.0。

### 二进制分帧（Binary Format）- http2.0的基石

http2.0之所以能够突破http1.X标准的性能限制，改进传输性能，实现低延迟和高吞吐量，就是因为其新增了二进制分帧层。

帧(frame)包含部分：类型Type, 长度Length, 标记Flags, 流标识Stream和frame payload有效载荷。

消息(message)：一个完整的请求或者响应，比如请求、响应等，由一个或多个 Frame 组成。

流是连接中的一个虚拟信道，可以承载双向消息传输。每个流有唯一整数标识符。为了防止两端流ID冲突，客户端发起的流具有奇数ID，服务器端发起的流具有偶数ID。

流标识是描述二进制frame的格式，使得每个frame能够基于http2发送，与流标识联系的是一个流，每个流是一个逻辑联系，一个独立的双向的frame存在于客户端和服务器端之间的http2连接中。一个http2连接上可包含多个并发打开的流，这个并发流的数量能够由客户端设置。

在二进制分帧层上，http2.0会将所有传输信息分割为更小的消息和帧，并对它们采用二进制格式的编码将其封装，新增的二进制分帧层同时也能够保证http的各种动词，方法，首部都不受影响，兼容上一代http标准。其中，http1.X中的首部信息header封装到Headers帧中，而request body将被封装到Data帧中。

![img](https://cdn.nlark.com/yuque/0/2023/webp/311219/1694250326573-16f29baf-000b-46e9-817f-fce8950e75c8.webp)

### 多路复用 (Multiplexing) / 连接共享

在http1.1中，浏览器客户端在同一时间，针对同一域名下的请求有一定数量的限制，超过限制数目的请求会被阻塞。这也是为何一些站点会有多个静态资源 CDN 域名的原因之一。

而http2.0中的多路复用优化了这一性能。多路复用允许同时通过单一的http/2 连接发起多重的请求-响应消息。有了新的分帧机制后，http/2 不再依赖多个TCP连接去实现多流并行了。每个数据流都拆分成很多互不依赖的帧，而这些帧可以交错（乱序发送），还可以分优先级，最后再在另一端把它们重新组合起来。

http 2.0 连接都是持久化的，而且客户端与服务器之间也只需要一个连接（每个域名一个连接）即可。http2连接可以承载数十或数百个流的复用，多路复用意味着来自很多流的数据包能够混合在一起通过同样连接传输。当到达终点时，再根据不同帧首部的流标识符重新连接将不同的数据流进行组装。

![img](https://cdn.nlark.com/yuque/0/2023/webp/311219/1694250326583-5859308d-a2c8-4fb5-bb78-798a92922724.webp)

上图展示了一个连接上的多个传输数据流：客户端向服务端传输数据帧stream5，同时服务端向客户端乱序发送stream1和stream3。这次连接上有三个响应请求乱序并行交换。

![img](https://cdn.nlark.com/yuque/0/2023/webp/311219/1694250326589-0e8cbdf1-db8a-4494-9ce1-55fcf13bc7e7.webp)

上图就是http1.X和http2.0在传输数据时的区别。以货物运输为例再现http1.1与http2.0的场景：

http1.1过程：货轮1从A地到B地去取货物，取到货物后，从B地返回，然后货轮2在A返回并卸下货物后才开始再从A地出发取货返回，如此有序往返。

http2.0过程：货轮1、2、3、4、5从A地无序全部出发，取货后返回，然后根据货轮号牌卸载对应货物。

显然，第二种方式运输货物多，河道的利用率高。

### 头部压缩（Header Compression）

http1.x的头带有大量信息，而且每次都要重复发送。http/2使用encoder来减少需要传输的header大小，通讯双方各自缓存一份头部字段表，既避免了重复header的传输，又减小了需要传输的大小。

对于相同的数据，不再通过每次请求和响应发送，通信期间几乎不会改变通用键-值对(用户代理、可接受的媒体类型，等等)只需发送一次。

事实上,如果请求中不包含首部(例如对同一资源的轮询请求)，那么，首部开销就是零字节，此时所有首部都自动使用之前请求发送的首部。

如果首部发生了变化，则只需将变化的部分加入到header帧中，改变的部分会加入到头部字段表中，首部表在 http 2.0 的连接存续期内始终存在，由客户端和服务器共同渐进地更新。

需要注意的是，http 2.0关注的是首部压缩，而我们常用的gzip等是报文内容（body）的压缩，二者不仅不冲突，且能够一起达到更好的压缩效果。

http/2使用的是专门为首部压缩而设计的HPACK②算法。

![img](https://cdn.nlark.com/yuque/0/2023/webp/311219/1694250326548-e340d1e7-26f2-4057-a1f3-653560eaf35f.webp)

从上图可以看到http1.X不支持首部压缩，而http2.0的压缩算法效果最好，发送和接受的数据量都是最少的。

### 压缩原理

用header字段表里的索引代替实际的header。

http/2的HPACK算法使用一份索引表来定义常用的http Header，把常用的 http Header 存放在表里，请求的时候便只需要发送在表里的索引位置即可。

例如 :method=GET 使用索引值 2 表示，:path=/index.html 使用索引值 5 表示，如下图：

![img](https://cdn.nlark.com/yuque/0/2023/webp/311219/1694250326552-05063157-2b84-4f8c-913d-b627e71e5ff4.webp)

完整的列表参考：HPACK Static Table③ 。

只要给服务端发送一个 Frame，该 Frame 的 Payload 部分存储 0x8285，Frame 的 Type 设置为 Header 类型，便可表示这个 Frame 属于 http Header，请求的内容是：

```plain
GET /index.html
```

为什么是 0x8285，而不是 0x0205？这是因为高位设置为 1 表示这个字节是一个完全索引值（key 和 value 都在索引中）。

类似的，通过高位的标志位可以区分出这个字节是属于一个完全索引值，还是仅索引了 key，还是 key和value 都没有索引(参见：HTTP/2首部压缩的OkHttp3实现④)。

因为索引表的大小的是有限的，它仅保存了一些常用的 http Header，同时每次请求还可以在表的末尾动态追加新的 http Header 缓存，动态部分称之为 Dynamic Table。Static Table 和 Dynamic Table 在一起组合成了索引表：

![img](https://cdn.nlark.com/yuque/0/2023/webp/311219/1694250326872-99b43e10-0603-4b72-9301-37b1dfd701f7.webp)

HPACK 不仅仅通过索引键值对来降低数据量，同时还会将字符串进行霍夫曼编码来压缩字符串大小。

以常用的 User-Agent 为例，它在静态表中的索引值是 58，它的值是不存在表中的，因为它的值是多变的。第一次请求的时候它的 key 用 58 表示，表示这是一个 User-Agent ，它的值部分会进行霍夫曼编码（如果编码后的字符串变更长了，则不采用霍夫曼编码）。

服务端收到请求后，会将这个 User-Agent 添加到 Dynamic Table 缓存起来，分配一个新的索引值。客户端下一次请求时，假设上次请求User-Agent的在表中的索引位置是 62， 此时只需要发送 0xBE（同样的，高位置 1），便可以代表：User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.146 Safari/537.36。

其过程如下图所示：

![img](https://cdn.nlark.com/yuque/0/2023/webp/311219/1694250326936-5a7292fc-1bcf-4e7b-8b36-0986bebac3c4.webp)

最终，相同的 Header 只需要发送索引值，新的 Header 会重新加入 Dynamic Table。

### 请求优先级（Request Priorities）

把http消息分为很多独立帧之后，就可以通过优化这些帧的交错和传输顺序进一步优化性能。每个流都可以带有一个31比特的优先值：0 表示最高优先级；2的31次方-1 表示最低优先级。

服务器可以根据流的优先级，控制资源分配（CPU、内存、带宽），而在响应数据准备好之后，优先将最高优先级的帧发送给客户端。高优先级的流都应该优先发送，但又不会绝对的。绝对地准守，可能又会引入首队阻塞的问题：高优先级的请求慢导致阻塞其他资源交付。

分配处理资源和客户端与服务器间的带宽，不同优先级的混合也是必须的。客户端会指定哪个流是最重要的，有一些依赖参数，这样一个流可以依赖另外一个流。优先级别可以在运行时动态改变，当用户滚动页面时，可以告诉浏览器哪个图像是最重要的，你也可以在一组流中进行优先筛选，能够突然抓住重点流。

- 优先级最高：主要的 html
- 优先级高：CSS 文件
- 优先级中：JS 文件
- 优先级低：图片

### 服务端推送（Server Push）

服务器可以对一个客户端请求发送多个响应，服务器向客户端推送资源无需客户端明确地请求。并且，服务端推送能把客户端所需要的资源伴随着index.html一起发送到客户端，省去了客户端重复请求的步骤。

正因为没有发起请求，建立连接等操作，所以静态资源通过服务端推送的方式可以极大地提升速度。Server Push 让 http1.x 时代使用内嵌资源的优化手段变得没有意义；如果一个请求是由你的主页发起的，服务器很可能会响应主页内容、logo 以及样式表，因为它知道客户端会用到这些东西，这相当于在一个 HTML 文档内集合了所有的资源。

不过与之相比，服务器推送还有一个很大的优势：可以缓存！也让在遵循同源的情况下，不同页面之间可以共享缓存资源成为可能。

![img](https://cdn.nlark.com/yuque/0/2023/webp/311219/1694250326940-465fa67c-9947-44d9-8871-ba9fa2224ac7.webp)

注意两点：

1、推送遵循同源策略；

2、这种服务端的推送是基于客户端的请求响应来确定的。

当服务端需要主动推送某个资源时，便会发送一个 Frame Type 为 PUSH_PROMISE 的 Frame，里面带了 PUSH 需要新建的 Stream ID。意思是告诉客户端：接下来我要用这个 ID 向你发送东西，客户端准备好接着。客户端解析 Frame 时，发现它是一个 PUSH_PROMISE 类型，便会准备接收服务端要推送的流。

### HTTP 2.0 的缺点

HTTP2 存在的问题：
1、如果有丢包请求会等待重传，阻塞后面的数据，有可能不如http1.1的多个TCP连接 TCP 以及 TCP+TLS 建立连接的延时
2、TCP 的队头阻塞并没有彻底解决 TCP 为了保证可靠传输，有一个“超时重传”机制，丢失的包必须等待重传确认
3、多路复用导致服务器压力上升，多路复用没有限制同时请求数。请求的平均数量与往常相同，但实际会有许多请求的短暂爆发，导致瞬时 QPS 暴增
4、多路复用容易 Timeout 大批量的请求同时发送，由于 HTTP2 连接内存在多个并行的流，而网络带宽和服务器资源有限，每个流的资源会被稀释，虽然它们开始时间相差更短，但却都可能超时。

## HTTP 3.0

HTTP3.0，也称作 HTTP over QUIC。HTTP3.0的核心是QUIC(读音quick)协议，由Google在2015年提出的SPDY v3演化而来的新协议，传统的HTTP协议是基于传输层TCP的协议，而QUIC是基于传输层UDP上的协议，可以定义成：HTTP3.0 基于 UDP 的安全可靠的 HTTP2.0 协议。

![img](https://cdn.nlark.com/yuque/0/2023/webp/311219/1694250537064-a6f88cea-3078-4b2a-9646-3d99f68875ce.webp) QUIC协议针对基于TCP和TLS的HTTP2.0协议解决了下面的问题：

1. **减少了TCP三次握手及TLS握手时间：** 不管是HTTP1.0/1.1还是 HTTPS，HTTP2.0，都使用了TCP进行传输。HTTPS和HTTP2还需要使用TLS协议来进行安全传输。这就出现了两个握手延迟，而基于UDP协议的QUIC，因为UDP 本身没有连接的概念，连接建立时只需要一次交互，半个握手的时间。区别如下图：![img](https://cdn.nlark.com/yuque/0/2023/webp/311219/1694250537049-9ed38d60-b818-4003-ac11-ce903bc56a86.webp)
2. **多路复用丢包时的线头阻塞问题：** QUIC保留了HTTP2.0多路复用的特性，但是即使在多路复用过程中，同一个TCP连接上有多个stream，假如其中一个stream丢包，在重传前后续的stream都会受到影响，而QUIC中一个连接上的多个stream之间没有依赖。所以当发生丢包时，只会影响当前的stream，也就避免了线头阻塞问题。
3. **优化重传策略：** 以往的TCP丢包重传策略是：在发送端为每一个封包标记一个编号 (sequence number)，接收端在收到封包时，就会回传一个带有对应编号的ACK封包给发送端，告知发送端封包已经确实收到。当发送端在超过一定时间之后还没有收到回传的 ACK，就会认为封包已经丢失，启动重新传送的机制，复用与原来相同的编号重新发送一次封包，确保在接收端这边没有任何封包漏接。 这样的机制就会带来一些问题，假设发送端总共对同一个封包发送了两次 (初始 + 重传)，使用的都是同一个sequence number：编号N。之后发送端在拿到编号N封包的回传ACK 时，将无法判断这个带有编号N的ACK，是接收端在收到初始封包后回传的ACK。这就会加大后续的重传计算的耗时。QUIC为了避免这个问题，发送端在传送封包时，初始与重传的每一个封包都改用一个新的编号，unique packet number，每一个编号都唯一而且严格递增，这样每次在收到ACK时，就可以依据编号明确的判断这个ACK是来自初始封包或者是重传封包。
4. **流量控制：** 通过流量控制可以限制客户端传输资料量的大小，有了流量控制后，接收端就可以只保留相对应大小的接收 buffer，优化记忆体被占用的空间。但是如果存在一个流量极慢的stream ，光一个stream就有可能佔用掉接收端所有的资源。QUIC为了避免这个潜在的HOL Blocking，采用了连线层 (connection flow control) 和 Stream 层的 (stream flow control) 流量控制，限制单一 Stream 可以占用的最大buffer size。
5. **连接迁移：** TCP连接基于四元组（源 IP、源端口、目的 IP、目的端口），切换网络时至少会有一个因素发生变化，导致连接发生变化。当连接发生变化时，如果还使用原来的 TCP 连接，则会导致连接失败，就得等原来的连接超时后重新建立连接，所以我们有时候发现切换到一个新网络时，即使新网络状况良好，但内容还是需要加载很久。如果实现得好，当检测到网络变化时立刻建立新的 TCP 连接，即使这样，建立新的连接还是需要几百毫秒的时间。 QUIC 的连接不受四元组的影响，当这四个元素发生变化时，原连接依然维持。QUIC 连接不以四元组作为标识，而是使用一个 64 位的随机数，这个随机数被称为 Connection ID，对应每个stream，即使 IP 或者端口发生变化，只要 Connection ID 没有变化，那么连接依然可以维持。